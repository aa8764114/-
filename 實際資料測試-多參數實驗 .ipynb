{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c2e058",
   "metadata": {},
   "source": [
    "## churn.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd2bcc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021 13:41:46 INFO Fit Columns Type Already Success!!!\n",
      "2021 13:41:46 INFO Transform Columns Type Success!!!\n",
      "2021 13:41:46 INFO scaler Success!!!\n",
      "2021 13:41:46 INFO dummies Success!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 87)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#放在不同資料夾用絕對路徑\n",
    "data = pd.read_csv('./data/churn.all.csv')\n",
    "\n",
    "#刪除不要的欄位\n",
    "data.drop(['id'], inplace=True, axis=1)\n",
    "data.drop(['phone_number'], inplace=True, axis=1)\n",
    "\n",
    "#將目標屬性轉為數字\n",
    "import numpy as np\n",
    "data['Churn'] = np.where(data['Churn'] == ' False', 0, 1)\n",
    "\n",
    "#分割輸入屬性及目標屬性\n",
    "\n",
    "#輸入屬性\n",
    "x_ = data.drop(['Churn'], axis=1)#同上方法刪除行\n",
    "\n",
    "#目標屬性\n",
    "y_ = data['Churn']\n",
    "\n",
    "#去除錯誤值及空值填補\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_pipeline import *\n",
    "from feature_engineering import *\n",
    "\n",
    "pipe = Pipeline(\n",
    "       [\n",
    "        ('define_column_type', define_column_type()),\n",
    "        ('scaler', scaler()),\n",
    "        ('dummies', dummies()),\n",
    "        #('filter', feature_selection(method = 'anova_kf', p_threshold = 1)),\n",
    "        #('sfs',feature_selection(method = 'sfs', sfs_direction = direction, sfs_scoring = scoring, sfs_cv = cv, sfs_estimator = estimator))\n",
    "       ])\n",
    "\n",
    "x_ = pipe.fit_transform(x_, y_)\n",
    "print(x_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47593bb4",
   "metadata": {},
   "source": [
    "## bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b08e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021 23:31:43 INFO Wrong Values has Filled as np.nan!!!\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]2021 23:31:43 INFO Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2021 23:31:43 INFO NumExpr defaulting to 8 threads.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:31:43] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:02<00:24,  2.25s/it]/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:31:45] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [00:12<01:06,  6.69s/it]/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:31:55] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [00:25<01:27,  9.69s/it]/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:08] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [00:27<00:54,  6.76s/it]/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:11] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [00:37<00:55,  7.91s/it]/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:21] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [00:42<00:42,  7.05s/it]/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [00:49<00:34,  6.95s/it]/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [01:11<00:47, 11.75s/it]/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:55] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [01:14<00:26,  8.87s/it]/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:57] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [01:18<00:14,  7.40s/it]/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:33:01] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [01:27<00:07,  7.85s/it]/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:33:10] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:28<00:00,  7.35s/it]\n",
      " 62%|██████▎   | 5/8 [00:13<00:07,  2.64s/it]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#放在不同資料夾用絕對路徑\n",
    "data = pd.read_csv('bank.csv')\n",
    "\n",
    "#刪除ID\n",
    "#data.drop(['id'], inplace=True, axis=1)\n",
    "\n",
    "#將目標屬性轉為數字\n",
    "import numpy as np\n",
    "data['y'] = np.where(data['y'] == 'no', 0, 1)\n",
    "\n",
    "#分割輸入屬性及目標屬性\n",
    "\n",
    "#輸入屬性\n",
    "x_ = data.drop(['y'], axis=1)#同上方法刪除行\n",
    "#x_ = data.drop(['phone_number'], axis=1)#同上方法刪除行\n",
    "\n",
    "#目標屬性\n",
    "y_ = data['y']\n",
    "\n",
    "#去除錯誤值及空值填補\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_pipeline import *\n",
    "from feature_engineering import *\n",
    "\n",
    "pipe = Pipeline(\n",
    "       [\n",
    "        ('Wrong_Value',wrong_value_fillna(wrong_value=['unknown'])),\n",
    "        ('Null_Value', xgb_fill()),\n",
    "        ('define_column_type', define_column_type()),\n",
    "        ('scaler', scaler()),\n",
    "        ('dummies', dummies()),\n",
    "       ])\n",
    "\n",
    "x_ = pipe.fit_transform(x_, y_)\n",
    "print(x_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34cbcb4",
   "metadata": {},
   "source": [
    "## WPBC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a01d2d",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "#放在不同資料夾用絕對路徑\n",
    "wpbc = pd.read_csv('wpbc.csv', header=None)\n",
    "\n",
    "#刪除ID\n",
    "wpbc.drop([0], inplace=True, axis=1)\n",
    "\n",
    "#將目標屬性轉為數字\n",
    "import numpy as np\n",
    "wpbc[1] = np.where(wpbc[1] == 'N', 0, 1)\n",
    "\n",
    "#分割輸入屬性及目標屬性\n",
    "\n",
    "#輸入屬性\n",
    "x_ = wpbc.drop([1], axis=1)#同上方法刪除行\n",
    "\n",
    "#目標屬性\n",
    "y_ = wpbc[1]\n",
    "\n",
    "#去除錯誤值及空值填補\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_pipeline import *\n",
    "from feature_engineering import *\n",
    "\n",
    "pipe = Pipeline(\n",
    "       [\n",
    "         ('Wrong_Value',wrong_value_fillna(wrong_value=['?'])),\n",
    "         ('column_type', define_column_type()),\n",
    "         #('Outlier', fix_outlier(how='quartile')), \n",
    "         \n",
    "         ('Null_Value', xgb_fill()),\n",
    "         #('num_log', num_log()),\n",
    "         \n",
    "         ('Wrong_Value2',wrong_value_fillna(wrong_value=[np.nan, float('-inf')])),\n",
    "         ('Null_Value2', xgb_fill()),\n",
    "  \n",
    "       ])\n",
    "\n",
    "x_ = pipe.fit_transform(x_, y_)\n",
    "print(x_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f533bd3f",
   "metadata": {},
   "source": [
    "## 用產生資料測試"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb960c5f",
   "metadata": {},
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "x_, y_ = make_classification(n_samples=5000, n_features=100,\n",
    "                             n_informative=60, n_redundant=20,\n",
    "                             n_classes=2, random_state=0, shuffle=True)\n",
    "\n",
    "x_ = pd.DataFrame(x_)\n",
    "y_ = pd.DataFrame(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ddf78b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc09e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#放在不同資料夾用絕對路徑\n",
    "data = pd.read_csv('./data/1.Annealing.csv', header=None)\n",
    "\n",
    "#將目標屬性轉為數字\n",
    "import numpy as np\n",
    "# data['Churn'] = np.where(data[38] == 'U', 0)\n",
    "data = data.replace('U', 0)\n",
    "\n",
    "\n",
    "#分割輸入屬性及目標屬性\n",
    "\n",
    "#輸入屬性\n",
    "x_ = data.drop([38], axis=1)#同上方法刪除行\n",
    "\n",
    "#目標屬性\n",
    "y_ = data[38]\n",
    "\n",
    "# #去除錯誤值及空值填補\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_pipeline import *\n",
    "from feature_engineering import *\n",
    "\n",
    "pipe = Pipeline(\n",
    "       [\n",
    "        ('Wrong_Value',wrong_value_fillna(wrong_value=['?'])),\n",
    "        ('filter', feature_selection(method = 'var')),\n",
    "        ('Null_Value', xgb_fill()),\n",
    "        ('define_column_type', define_column_type()),\n",
    "#         ('dummies', dummies()),\n",
    "#         ('scaler', scaler()),\n",
    "       ])\n",
    "\n",
    "x_ = pipe.fit_transform(x_, y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986a285f",
   "metadata": {},
   "source": [
    "## 2.Statlog (Australian Credit Approval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a871eab4",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "#放在不同資料夾用絕對路徑\n",
    "data = pd.read_csv('./data/2.Statlog (Australian Credit Approval).csv', header=None)\n",
    "\n",
    "#輸入屬性\n",
    "x_ = data.drop([14], axis=1)#同上方法刪除行\n",
    "\n",
    "#目標屬性\n",
    "y_ = data[14]\n",
    "\n",
    "#去除錯誤值及空值填補\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_pipeline import *\n",
    "from feature_engineering import *\n",
    "\n",
    "pipe = Pipeline(\n",
    "       [\n",
    "        ('define_column_type', define_column_type()),\n",
    "        ('filter', feature_selection(method = 'sys')),\n",
    "\n",
    "#         ('scaler', scaler()),\n",
    "#         ('dummies', dummies()),\n",
    "       ])\n",
    "\n",
    "x_ = pipe.fit_transform(x_, y_)\n",
    "print(x_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1eef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976cf87c",
   "metadata": {},
   "source": [
    "## 6.default of credit card clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5026d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#放在不同資料夾用絕對路徑\n",
    "data = pd.read_csv('./data/6.default of credit card clients.csv')\n",
    "\n",
    "#輸入屬性\n",
    "x_ = data.drop(['default payment next month'], axis=1)#同上方法刪除行\n",
    "\n",
    "#目標屬性\n",
    "y_ = data['default payment next month']\n",
    "\n",
    "#去除錯誤值及空值填補\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_pipeline import *\n",
    "from feature_engineering import *\n",
    "\n",
    "pipe = Pipeline(\n",
    "       [\n",
    "        ('define_column_type', define_column_type()),\n",
    "#         ('scaler', scaler()),\n",
    "         ('dummies', dummies()),\n",
    "#         ('filter', feature_selection(method = 'anova_kf', p_threshold = 1)),\n",
    "#         ('sfs',feature_selection(method = 'sfs', sfs_direction = direction, sfs_scoring = scoring, sfs_cv = cv, sfs_estimator = estimator))\n",
    "       ])\n",
    "\n",
    "x_ = pipe.fit_transform(x_, y_)\n",
    "print(x_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c4c808",
   "metadata": {},
   "source": [
    "## 將index轉換為欄位名稱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbe33e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_colname(indexs, oridata):\n",
    "    colname = []\n",
    "    for i in indexs:\n",
    "        colname.append(list(x_.columns)[i])\n",
    "    \n",
    "    return(colname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e20c72a",
   "metadata": {},
   "source": [
    "## 輸入模型將屬性重要性轉為index輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e083f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_to_index(clf, prob):\n",
    "    importances = list(clf.feature_importances_)\n",
    "    s = importances\n",
    "    s2 = sorted(range(len(s)), key=lambda k: s[k], reverse=True)\n",
    "    return s2[:int(len(s2)*prob)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773ebb11",
   "metadata": {},
   "source": [
    "## 交叉驗證AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ac4d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算AUC函數\n",
    "def get_auc(model, x, y):\n",
    "    \n",
    "    '''\n",
    "    model : 用甚麼方式建模\n",
    "    x : 輸入屬性\n",
    "    y : 目標屬性\n",
    "    '''\n",
    "    import numpy as np\n",
    "    from sklearn import metrics\n",
    "    \n",
    "    #建模\n",
    "    #model.fit(x, y)\n",
    "\n",
    "    #用訓練資料測試\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, model.predict(x))\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    print('這次的AUC : ', auc,'\\n')\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931a48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算f1函數\n",
    "def get_f1(model, x, y):\n",
    "    \n",
    "    '''\n",
    "    model : 用甚麼方式建模\n",
    "    x : 輸入屬性\n",
    "    y : 目標屬性\n",
    "    '''\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import f1_score\n",
    "    \n",
    "    #建模\n",
    "    #model.fit(x, y)\n",
    "\n",
    "    #用訓練資料測試\n",
    "    f1 = f1_score(y, model.predict(x), average='binary')\n",
    "\n",
    "    print('這次的f1 : ', f1,'\\n')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd09462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifierZe\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#交叉驗證，分層隨機抽樣\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random as rd\n",
    "\n",
    "\n",
    "\n",
    "# fs_method = ['anova_kf', 'gini', 'entropy', 'rf_gini', 'rf_entropy', 'xgb', 'corr', 'var', False]\n",
    "fs_method = ['corr']\n",
    "\n",
    "\n",
    "\n",
    "for fsMethod in fs_method:\n",
    "    \n",
    "    f1 = [] #存不同方法的交叉驗證平均f1\n",
    "    AUC = [] #存不同方法的交叉驗證平均AUC\n",
    "    \n",
    "    ans_auc = [] #儲存每次交叉驗證的AUC\n",
    "    ans_f1 = [] #儲存每次交叉驗證的f1\n",
    "\n",
    "    rand = rd.randint(1, 10) #產生交叉驗證抽樣隨機種子\n",
    "    skf = StratifiedKFold(n_splits=10, random_state = rand, shuffle=True)\n",
    "\n",
    "    for train_index, test_index in skf.split(x_, y_):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index,'\\n')\n",
    "        x_train, x_test = x_.iloc[train_index], x_.iloc[test_index]\n",
    "        y_train, y_test = y_.iloc[train_index], y_.iloc[test_index]\n",
    "\n",
    "        x_train = pd.DataFrame(x_train)\n",
    "        y_train = pd.DataFrame(y_train)\n",
    "\n",
    "        x_test = pd.DataFrame(x_test)\n",
    "        y_test = pd.DataFrame(y_test)   \n",
    "\n",
    "\n",
    "\n",
    "#         clf = AdaBoostClassifier(base_estimator=GaussianNB(), n_estimators=100, random_state=0, algorithm='SAMME')\n",
    "#         clf = GaussianNB()\n",
    "        clf = AdaBoostClassifierZe(base_estimator=GaussianNB(), n_estimators=100, random_state=0, algorithm='SAMME.R', fs_enable=fsMethod)\n",
    "#         clf = AdaBoostClassifierZe(base_estimator=SVC(probability=True), n_estimators=100, random_state=0, algorithm='SAMME.R', fs_enable=fsMethod)\n",
    "#         clf = AdaBoostClassifierZe(n_estimators=100, random_state=0, algorithm='SAMME.R', fs_enable=fsMethod)\n",
    "#         clf = AdaBoostClassifier(n_estimators=100, random_state=0, algorithm='SAMME.R')\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        ans_f1.append(get_f1(clf,x_test,y_test)) #取得用測試資料測試的f1\n",
    "        ans_auc.append(get_auc(clf,x_test,y_test)) #取得用測試資料測試的AUC\n",
    "\n",
    "    #一個方法的十折交叉驗證平均\n",
    "    AUC.append(np.mean(ans_auc))\n",
    "    f1.append(np.mean(ans_f1))\n",
    "    print('ans_auc : ', ans_auc)\n",
    "    print('ans_f1 : ', ans_f1)\n",
    "        \n",
    "    print(\"==========\", fsMethod, \"==========\")\n",
    "    print(AUC)\n",
    "    print(f1)\n",
    "    print(\"==================================\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6d7853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
