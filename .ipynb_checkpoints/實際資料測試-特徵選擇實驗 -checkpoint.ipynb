{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd2af290",
   "metadata": {},
   "source": [
    "## churn.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75bbdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#放在不同資料夾用絕對路徑\n",
    "data = pd.read_csv('./data/churn.all.csv')\n",
    "\n",
    "#刪除不要的欄位\n",
    "data.drop(['id'], inplace=True, axis=1)\n",
    "data.drop(['phone_number'], inplace=True, axis=1)\n",
    "\n",
    "#將目標屬性轉為數字\n",
    "import numpy as np\n",
    "data['Churn'] = np.where(data['Churn'] == ' False', 0, 1)\n",
    "\n",
    "#分割輸入屬性及目標屬性\n",
    "\n",
    "#輸入屬性\n",
    "x_ = data.drop(['Churn'], axis=1)#同上方法刪除行\n",
    "\n",
    "#目標屬性\n",
    "y_ = data['Churn']\n",
    "\n",
    "#去除錯誤值及空值填補\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_pipeline import *\n",
    "from feature_engineering import *\n",
    "\n",
    "pipe = Pipeline(\n",
    "       [\n",
    "        ('define_column_type', define_column_type()),\n",
    "        ('scaler', scaler()),\n",
    "        ('dummies', dummies()),\n",
    "        #('filter', feature_selection(method = 'anova_kf', p_threshold = 1)),\n",
    "        #('sfs',feature_selection(method = 'sfs', sfs_direction = direction, sfs_scoring = scoring, sfs_cv = cv, sfs_estimator = estimator))\n",
    "       ])\n",
    "\n",
    "x_ = pipe.fit_transform(x_, y_)\n",
    "print(x_.shape)\n",
    "\n",
    "import collections\n",
    "c = collections.Counter(y_)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e056a462",
   "metadata": {},
   "source": [
    "## bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bd7647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#放在不同資料夾用絕對路徑\n",
    "data = pd.read_csv('./data/bank.csv')\n",
    "\n",
    "#刪除ID\n",
    "#data.drop(['id'], inplace=True, axis=1)\n",
    "\n",
    "#將目標屬性轉為數字\n",
    "import numpy as np\n",
    "data['y'] = np.where(data['y'] == 'no', 0, 1)\n",
    "\n",
    "#分割輸入屬性及目標屬性\n",
    "\n",
    "#輸入屬性\n",
    "x_ = data.drop(['y'], axis=1)#同上方法刪除行\n",
    "#x_ = data.drop(['phone_number'], axis=1)#同上方法刪除行\n",
    "\n",
    "#目標屬性\n",
    "y_ = data['y']\n",
    "\n",
    "#去除錯誤值及空值填補\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_pipeline import *\n",
    "from feature_engineering import *\n",
    "\n",
    "pipe = Pipeline(\n",
    "       [\n",
    "#         ('Wrong_Value',wrong_value_fillna(wrong_value=['unknown'])),\n",
    "#         ('Null_Value', xgb_fill()),\n",
    "        ('define_column_type', define_column_type()),\n",
    "        ('scaler', scaler()),\n",
    "        ('dummies', dummies()),\n",
    "       ])\n",
    "\n",
    "x_ = pipe.fit_transform(x_, y_)\n",
    "print(x_.shape)\n",
    "\n",
    "import collections\n",
    "c = collections.Counter(y_)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce6aec7",
   "metadata": {},
   "source": [
    "## WPBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5491c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#放在不同資料夾用絕對路徑\n",
    "wpbc = pd.read_csv('./data/wpbc.csv', header=None)\n",
    "\n",
    "#刪除ID\n",
    "wpbc.drop([0], inplace=True, axis=1)\n",
    "\n",
    "#將目標屬性轉為數字\n",
    "import numpy as np\n",
    "wpbc[1] = np.where(wpbc[1] == 'N', 0, 1)\n",
    "\n",
    "#分割輸入屬性及目標屬性\n",
    "\n",
    "#輸入屬性\n",
    "x_ = wpbc.drop([1], axis=1)#同上方法刪除行\n",
    "\n",
    "#目標屬性\n",
    "y_ = wpbc[1]\n",
    "\n",
    "#去除錯誤值及空值填補\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_pipeline import *\n",
    "from feature_engineering import *\n",
    "\n",
    "pipe = Pipeline(\n",
    "       [\n",
    "         ('Wrong_Value',wrong_value_fillna(wrong_value=['?'])),\n",
    "         ('column_type', define_column_type()),\n",
    "         #('Outlier', fix_outlier(how='quartile')), \n",
    "         \n",
    "         ('Null_Value', xgb_fill()),\n",
    "         #('num_log', num_log()),\n",
    "         \n",
    "         ('Wrong_Value2',wrong_value_fillna(wrong_value=[np.nan, float('-inf')])),\n",
    "         ('Null_Value2', xgb_fill()),\n",
    "  \n",
    "       ])\n",
    "\n",
    "x_ = pipe.fit_transform(x_, y_)\n",
    "print(x_.shape)\n",
    "\n",
    "import collections\n",
    "c = collections.Counter(y_)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980986c7",
   "metadata": {},
   "source": [
    "## 2.Statlog (Australian Credit Approval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#澳大利亞信貸審批，沒說目標屬性哪個是通過不通過\n",
    "import pandas as pd\n",
    "\n",
    "#放在不同資料夾用絕對路徑\n",
    "data = pd.read_csv('./data/2.australian.csv', header=None)\n",
    "\n",
    "#輸入屬性\n",
    "x_ = data.drop([14], axis=1)#同上方法刪除行\n",
    "\n",
    "#目標屬性\n",
    "y_ = data[14]\n",
    "\n",
    "#去除錯誤值及空值填補\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_pipeline import *\n",
    "from feature_engineering import *\n",
    "\n",
    "pipe = Pipeline(\n",
    "       [\n",
    "        ('define_column_type', define_column_type()),\n",
    "        ('scaler', scaler()),\n",
    "       ])\n",
    "\n",
    "x_ = pipe.fit_transform(x_, y_)\n",
    "print(x_.shape)\n",
    "\n",
    "import collections\n",
    "c = collections.Counter(y_)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daada69",
   "metadata": {},
   "source": [
    "## 6.default of credit card clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53a61cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#客戶信用卡資料，下個月是否付款\n",
    "import pandas as pd\n",
    "\n",
    "#放在不同資料夾用絕對路徑\n",
    "data = pd.read_csv('./data/6.default of credit card clients.csv')\n",
    "\n",
    "#輸入屬性\n",
    "x_ = data.drop(['default payment next month'], axis=1)#同上方法刪除行\n",
    "\n",
    "#目標屬性\n",
    "y_ = data['default payment next month']\n",
    "\n",
    "#去除錯誤值及空值填補\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_pipeline import *\n",
    "from feature_engineering import *\n",
    "\n",
    "pipe = Pipeline(\n",
    "       [\n",
    "        ('define_column_type', define_column_type()),\n",
    "        ('scaler', scaler()),\n",
    "        ('dummies', dummies()),\n",
    "        #('filter', feature_selection(method = 'anova_kf', p_threshold = 1)),\n",
    "        #('sfs',feature_selection(method = 'sfs', sfs_direction = direction, sfs_scoring = scoring, sfs_cv = cv, sfs_estimator = estimator))\n",
    "       ])\n",
    "\n",
    "x_ = pipe.fit_transform(x_, y_)\n",
    "print(x_.shape)\n",
    "\n",
    "import collections\n",
    "c = collections.Counter(y_)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315bfa97",
   "metadata": {},
   "source": [
    "## 9.hepatitis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db50fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#病人資訊（肝炎）->是否死\n",
    "import pandas as pd\n",
    "\n",
    "#放在不同資料夾用絕對路徑\n",
    "data = pd.read_csv('./data/9.hepatitis.csv', header=None)\n",
    "\n",
    "#將目標屬性轉為數字\n",
    "import numpy as np\n",
    "data[0] = np.where(data[0] == 2, 0, 1)\n",
    "\n",
    "#輸入屬性\n",
    "x_ = data.drop([0], axis=1)#同上方法刪除行\n",
    "\n",
    "#目標屬性\n",
    "y_ = data[0]\n",
    "\n",
    "#去除錯誤值及空值填補\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_pipeline import *\n",
    "from feature_engineering import *\n",
    "\n",
    "pipe = Pipeline(\n",
    "       [\n",
    "        ('Wrong_Value',wrong_value_fillna(wrong_value=['?'])),\n",
    "        ('filter', feature_selection(method = 'var')),\n",
    "        ('Null_Value', xgb_fill()),\n",
    "        ('define_column_type', define_column_type()),\n",
    "#         ('dummies', dummies()),\n",
    "       ])\n",
    "\n",
    "x_ = pipe.fit_transform(x_, y_)\n",
    "print(x_.shape)\n",
    "\n",
    "import collections\n",
    "c = collections.Counter(y_)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ba978b",
   "metadata": {},
   "source": [
    "## 11.ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b6d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#電離層的雷達回波分類好壞\n",
    "import pandas as pd\n",
    "\n",
    "#放在不同資料夾用絕對路徑\n",
    "data = pd.read_csv('./data/11.ionosphere.csv', header=None)\n",
    "\n",
    "#刪除不要的欄位\n",
    "data.drop([0], inplace=True, axis=1)\n",
    "\n",
    "#將目標屬性轉為數字\n",
    "import numpy as np\n",
    "data[34] = np.where(data[34] == 'g', 1, 0)\n",
    "\n",
    "#輸入屬性\n",
    "x_ = data.drop([34], axis=1)#同上方法刪除行\n",
    "\n",
    "#目標屬性\n",
    "y_ = data[34]\n",
    "\n",
    "#去除錯誤值及空值填補\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_pipeline import *\n",
    "from feature_engineering import *\n",
    "\n",
    "pipe = Pipeline(\n",
    "       [\n",
    "        ('define_column_type', define_column_type()),\n",
    "#         ('dummies', dummies()),\n",
    "       ])\n",
    "\n",
    "x_ = pipe.fit_transform(x_, y_)\n",
    "print(x_.shape)\n",
    "\n",
    "import collections\n",
    "c = collections.Counter(y_)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36011a18",
   "metadata": {},
   "source": [
    "## 16.sonar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b0bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分類聲納訊號掃到的是岩石（Ｒ）或金屬圓柱（Ｍ）\n",
    "import pandas as pd\n",
    "\n",
    "#放在不同資料夾用絕對路徑\n",
    "data = pd.read_csv('./data/16.sonar.csv', header=None)\n",
    "\n",
    "#將目標屬性轉為數字\n",
    "import numpy as np\n",
    "data[60] = np.where(data[60] == 'R', 0, 1)\n",
    "\n",
    "#輸入屬性\n",
    "x_ = data.drop([60], axis=1)#同上方法刪除行\n",
    "\n",
    "#目標屬性\n",
    "y_ = data[60]\n",
    "\n",
    "#去除錯誤值及空值填補\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_pipeline import *\n",
    "from feature_engineering import *\n",
    "\n",
    "pipe = Pipeline(\n",
    "       [\n",
    "        ('define_column_type', define_column_type()),\n",
    "#         ('dummies', dummies()),\n",
    "       ])\n",
    "\n",
    "x_ = pipe.fit_transform(x_, y_)\n",
    "print(x_.shape)\n",
    "\n",
    "import collections\n",
    "c = collections.Counter(y_)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff60122",
   "metadata": {},
   "source": [
    "## 17.tic-tac-toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c09c9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#井字遊戲，positive (i.e., wins for \"x\")\n",
    "import pandas as pd\n",
    "\n",
    "#放在不同資料夾用絕對路徑\n",
    "data = pd.read_csv('./data/17.tic-tac-toe.csv', header=None)\n",
    "\n",
    "#將目標屬性轉為數字\n",
    "import numpy as np\n",
    "data[9] = np.where(data[9] == 'negative', 0, 1)\n",
    "\n",
    "#輸入屬性\n",
    "x_ = data.drop([9], axis=1)#同上方法刪除行\n",
    "\n",
    "#目標屬性\n",
    "y_ = data[9]\n",
    "\n",
    "#去除錯誤值及空值填補\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_pipeline import *\n",
    "from feature_engineering import *\n",
    "\n",
    "pipe = Pipeline(\n",
    "       [\n",
    "        ('define_column_type', define_column_type()),\n",
    "        ('dummies', dummies()),\n",
    "       ])\n",
    "\n",
    "x_ = pipe.fit_transform(x_, y_)\n",
    "print(x_.shape)\n",
    "\n",
    "import collections\n",
    "c = collections.Counter(y_)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49d9a6",
   "metadata": {},
   "source": [
    "## 21.broadband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#電信客戶流失\n",
    "import pandas as pd\n",
    "\n",
    "#放在不同資料夾用絕對路徑\n",
    "data = pd.read_csv('./data/21.broadband.csv')\n",
    "\n",
    "#刪除不要的欄位\n",
    "data.drop(['CUST_ID'], inplace=True, axis=1)\n",
    "\n",
    "#輸入屬性\n",
    "x_ = data.drop(['BROADBAND'], axis=1)#同上方法刪除行\n",
    "\n",
    "#目標屬性\n",
    "y_ = data['BROADBAND']\n",
    "\n",
    "#去除錯誤值及空值填補\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_pipeline import *\n",
    "from feature_engineering import *\n",
    "\n",
    "pipe = Pipeline(\n",
    "       [\n",
    "        ('define_column_type', define_column_type()),\n",
    "        ('dummies', dummies()),\n",
    "       ])\n",
    "\n",
    "x_ = pipe.fit_transform(x_, y_)\n",
    "print(x_.shape)\n",
    "\n",
    "import collections\n",
    "c = collections.Counter(y_)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbea2db",
   "metadata": {},
   "source": [
    "## 用產生資料測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dfb808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "x_, y_ = make_classification(n_samples=5000, n_features=100,\n",
    "                             n_informative=80, n_redundant=20,\n",
    "                             n_classes=2, random_state=0, shuffle=True)\n",
    "\n",
    "x_ = pd.DataFrame(x_)\n",
    "y_ = pd.DataFrame(y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e49942",
   "metadata": {},
   "source": [
    "## 將index轉換為欄位名稱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19ffb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_colname(indexs, oridata):\n",
    "    colname = []\n",
    "    for i in indexs:\n",
    "        colname.append(list(x_.columns)[i])\n",
    "    \n",
    "    return(colname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3e3569",
   "metadata": {},
   "source": [
    "## 輸入模型將屬性重要性轉為index輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c88d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_to_index(feature_importances_, prob):\n",
    "    importances = list(feature_importances_)\n",
    "    s = importances\n",
    "    s2 = sorted(range(len(s)), key=lambda k: s[k], reverse=True)\n",
    "    return s2[:int(len(s2)*prob)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3baf14",
   "metadata": {},
   "source": [
    "## 交叉驗證AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae47678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算AUC函數\n",
    "def get_auc(model, x, y):\n",
    "    \n",
    "    '''\n",
    "    model : 用甚麼方式建模\n",
    "    x : 輸入屬性\n",
    "    y : 目標屬性\n",
    "    '''\n",
    "    import numpy as np\n",
    "    from sklearn import metrics\n",
    "    \n",
    "    #建模\n",
    "    #model.fit(x, y)\n",
    "\n",
    "    #用訓練資料測試\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, model.predict(x))\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    print('這次的AUC : ', auc,'\\n')\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806dc5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算f1函數\n",
    "def get_f1(model, x, y):\n",
    "    \n",
    "    '''\n",
    "    model : 用甚麼方式建模\n",
    "    x : 輸入屬性\n",
    "    y : 目標屬性\n",
    "    '''\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import f1_score\n",
    "    \n",
    "    #建模\n",
    "    #model.fit(x, y)\n",
    "\n",
    "    #用訓練資料測試\n",
    "    f1 = f1_score(y, model.predict(x), average='binary')\n",
    "\n",
    "    print('這次的f1 : ', f1,'\\n')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc07762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifierZe\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#交叉驗證，分層隨機抽樣\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random as rd\n",
    "\n",
    "\n",
    "#'corr', 'var'：測試階段\n",
    "# fs_method = ['anova_kf', 'gini', 'entropy', 'rf_gini', 'rf_entropy', 'xgb', 'corr', 'var', False]\n",
    "fs_method = ['entropy', 'gini', 'rf_entropy', 'rf_gini', 'xgb']\n",
    "# fs_method = ['anova_kf']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for fsMethod in fs_method:\n",
    "    \n",
    "    f1 = [] #存不同方法的交叉驗證平均f1\n",
    "    AUC = [] #存不同方法的交叉驗證平均AUC\n",
    "    \n",
    "    ans_auc = [] #儲存每次交叉驗證的AUC\n",
    "    ans_f1 = [] #儲存每次交叉驗證的f1\n",
    "\n",
    "    rand = rd.randint(1, 10) #產生交叉驗證抽樣隨機種子\n",
    "    skf = StratifiedKFold(n_splits=10, random_state = rand, shuffle=True)\n",
    "\n",
    "    for train_index, test_index in skf.split(x_, y_):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index,'\\n')\n",
    "        x_train, x_test = x_.iloc[train_index], x_.iloc[test_index]\n",
    "        y_train, y_test = y_.iloc[train_index], y_.iloc[test_index]\n",
    "\n",
    "        x_train = pd.DataFrame(x_train)\n",
    "        y_train = pd.DataFrame(y_train)\n",
    "\n",
    "        x_test = pd.DataFrame(x_test)\n",
    "        y_test = pd.DataFrame(y_test)   \n",
    "\n",
    "\n",
    "        #選擇建模方法\n",
    "        clf = AdaBoostClassifierZe(base_estimator=GaussianNB(), n_estimators=100, random_state=0, algorithm='SAMME', fs_enable=fsMethod)\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "        features = importance_to_index(clf.get_my_feature_importance(), 0.2)\n",
    "        clf2 = GaussianNB()\n",
    "        clf2.fit(x_train[index_to_colname(features, x_train)], y_train)\n",
    "\n",
    "\n",
    "        ans_f1.append(get_f1(clf2,x_test[index_to_colname(features, x_train)], y_test)) #取得用測試資料測試的f1\n",
    "        ans_auc.append(get_auc(clf2,x_test[index_to_colname(features, x_train)], y_test)) #取得用測試資料測試的AUC\n",
    "\n",
    "    #一個方法的十折交叉驗證平均\n",
    "    AUC.append(np.mean(ans_auc))\n",
    "    f1.append(np.mean(ans_f1))\n",
    "    print('ans_auc : ', ans_auc)\n",
    "    print('ans_f1 : ', ans_f1)\n",
    "        \n",
    "    print(\"==========\", fsMethod, \"==========\")\n",
    "    print(AUC)\n",
    "#     print(f1)\n",
    "    print(\"==================================\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769d7788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifierZe\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "#交叉驗證，分層隨機抽樣\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random as rd\n",
    "\n",
    "ans_auc = [] #儲存每次交叉驗證的AUC\n",
    "ans_f1 = [] #儲存每次交叉驗證的f1\n",
    "\n",
    "rand = rd.randint(1, 10) #產生交叉驗證抽樣隨機種子\n",
    "skf = StratifiedKFold(n_splits=10, random_state = rand, shuffle=True)\n",
    "\n",
    "for train_index, test_index in skf.split(x_, y_):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index,'\\n')\n",
    "    x_train, x_test = x_.iloc[train_index], x_.iloc[test_index]\n",
    "    y_train, y_test = y_.iloc[train_index], y_.iloc[test_index]\n",
    "\n",
    "    x_train = pd.DataFrame(x_train)\n",
    "    y_train = pd.DataFrame(y_train)\n",
    "\n",
    "    x_test = pd.DataFrame(x_test)\n",
    "    y_test = pd.DataFrame(y_test)   \n",
    "\n",
    "\n",
    "    #選擇建模方法\n",
    "    clf = AdaBoostClassifier(n_estimators=100, algorithm='SAMME', random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    importance = clf.feature_importances_\n",
    "    features = importance_to_index(importance, 0.2)\n",
    "    clf2 = GaussianNB()\n",
    "    clf2.fit(x_train[index_to_colname(features, x_train)], y_train)\n",
    "\n",
    "    ans_f1.append(get_f1(clf2,x_test[index_to_colname(features, x_train)], y_test)) #取得用測試資料測試的f1\n",
    "    ans_auc.append(get_auc(clf2,x_test[index_to_colname(features, x_train)], y_test)) #取得用測試資料測試的AUC\n",
    "\n",
    "#一個方法的十折交叉驗證平均\n",
    "print('ans_auc : ', np.mean(ans_auc))\n",
    "# print('ans_f1 : ', np.mean(ans_f1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
